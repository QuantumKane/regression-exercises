{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydataset import data\n",
    "import wrangle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ryan's functions\n",
    "\n",
    "def train_validate_test(df, target):\n",
    "    '''\n",
    "    this function takes in a dataframe and splits it into 3 samples, \n",
    "    a test, which is 20% of the entire dataframe, \n",
    "    a validate, which is 24% of the entire dataframe,\n",
    "    and a train, which is 56% of the entire dataframe. \n",
    "    It then splits each of the 3 samples into a dataframe with independent variables\n",
    "    and a series with the dependent, or target variable. \n",
    "    The function returns 3 dataframes and 3 series:\n",
    "    X_train (df) & y_train (series), X_validate & y_validate, X_test & y_test. \n",
    "    '''\n",
    "    # split df into test (20%) and train_validate (80%)\n",
    "    train_validate, test = train_test_split(df, test_size=.2, random_state=123)\n",
    "\n",
    "    # split train_validate off into train (70% of 80% = 56%) and validate (30% of 80% = 24%)\n",
    "    train, validate = train_test_split(train_validate, test_size=.3, random_state=123)\n",
    "\n",
    "        \n",
    "    # split train into X (dataframe, drop target) & y (series, keep target only)\n",
    "    X_train = train.drop(columns=[target])\n",
    "    y_train = train[target]\n",
    "    \n",
    "    # split validate into X (dataframe, drop target) & y (series, keep target only)\n",
    "    X_validate = validate.drop(columns=[target])\n",
    "    y_validate = validate[target]\n",
    "    \n",
    "    # split test into X (dataframe, drop target) & y (series, keep target only)\n",
    "    X_test = test.drop(columns=[target])\n",
    "    y_test = test[target]\n",
    "    \n",
    "    return X_train, y_train, X_validate, y_validate, X_test, y_test\n",
    "\n",
    "def get_numeric_X_cols(X_train, object_cols):\n",
    "    '''\n",
    "    takes in a dataframe and list of object column names\n",
    "    and returns a list of all other columns names, the non-objects. \n",
    "    '''\n",
    "    numeric_cols = [col for col in X_train.columns.values if col not in object_cols]\n",
    "    \n",
    "    return numeric_cols\n",
    "\n",
    "\n",
    "def min_max_scale(X_train, X_validate, X_test, numeric_cols):\n",
    "    '''\n",
    "    this function takes in 3 dataframes with the same columns, \n",
    "    a list of numeric column names (because the scaler can only work with numeric columns),\n",
    "    and fits a min-max scaler to the first dataframe and transforms all\n",
    "    3 dataframes using that scaler. \n",
    "    it returns 3 dataframes with the same column names and scaled values. \n",
    "    '''\n",
    "    # create the scaler object and fit it to X_train (i.e. identify min and max)\n",
    "    # if copy = false, inplace row normalization happens and avoids a copy (if the input is already a numpy array).\n",
    "\n",
    "\n",
    "    scaler = MinMaxScaler(copy=True).fit(X_train[numeric_cols])\n",
    "\n",
    "    #scale X_train, X_validate, X_test using the mins and maxes stored in the scaler derived from X_train. \n",
    "    # \n",
    "    X_train_scaled_array = scaler.transform(X_train[numeric_cols])\n",
    "    X_validate_scaled_array = scaler.transform(X_validate[numeric_cols])\n",
    "    X_test_scaled_array = scaler.transform(X_test[numeric_cols])\n",
    "\n",
    "    # convert arrays to dataframes\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled_array, \n",
    "                                  columns=numeric_cols).\\\n",
    "                                  set_index([X_train.index.values])\n",
    "\n",
    "    X_validate_scaled = pd.DataFrame(X_validate_scaled_array, \n",
    "                                     columns=numeric_cols).\\\n",
    "                                     set_index([X_validate.index.values])\n",
    "\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled_array, \n",
    "                                 columns=numeric_cols).\\\n",
    "                                 set_index([X_test.index.values])\n",
    "\n",
    "    \n",
    "    return X_train_scaled, X_validate_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ryan's functions2\n",
    "\n",
    "def create_dummies(df, object_cols):\n",
    "    '''\n",
    "    This function takes in a dataframe and list of object column names,\n",
    "    and creates dummy variables of each of those columns. \n",
    "    It then appends the dummy variables to the original dataframe. \n",
    "    It returns the original df with the appended dummy variables. \n",
    "    '''\n",
    "    \n",
    "    # run pd.get_dummies() to create dummy vars for the object columns. \n",
    "    # we will drop the column representing the first unique value of each variable\n",
    "    # we will opt to not create na columns for each variable with missing values \n",
    "    # (all missing values have been removed.)\n",
    "    dummy_df = pd.get_dummies(object_cols, dummy_na=False, drop_first=True)\n",
    "    \n",
    "    # concatenate the dataframe with dummies to our original dataframe\n",
    "    # via column (axis=1)\n",
    "    df = pd.concat([df, dummy_df], axis=1)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_object_cols(df):\n",
    "    '''\n",
    "    This function takes in a dataframe and identifies the columns that are object types\n",
    "    and returns a list of those column names. \n",
    "    '''\n",
    "    # create a mask of columns whether they are object type or not\n",
    "    mask = np.array(df.dtypes == \"object\")\n",
    "\n",
    "        \n",
    "    # get a list of the column names that are objects (from the mask)\n",
    "    object_cols = df.iloc[:, mask].columns.tolist()\n",
    "    \n",
    "    return object_cols\n",
    "\n",
    "def wrangle_tips(df):\n",
    "    df = data('tips')\n",
    "    \n",
    "    # drop any nulls\n",
    "    df = df[~df.isnull()]\n",
    "\n",
    "    # get object column names\n",
    "    object_cols = get_object_cols(df)\n",
    "    \n",
    "    # create dummy vars\n",
    "    df = create_dummies(df, object_cols)\n",
    "      \n",
    "    # split data \n",
    "    X_train, y_train, X_validate, y_validate, X_test, y_test = train_validate_test(df, 'tip')\n",
    "    \n",
    "    # get numeric column names\n",
    "    numeric_cols = get_numeric_X_cols(X_train, object_cols)\n",
    "\n",
    "    # scale data \n",
    "    X_train_scaled, X_validate_scaled, X_test_scaled = min_max_scale(X_train, X_validate, X_test, numeric_cols)\n",
    "    \n",
    "    return df, X_train, X_train_scaled, y_train, X_validate_scaled, y_validate, X_test_scaled, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load the tips dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load my dataset\n",
    "\n",
    "df, X_train_explore, \\\n",
    "    X_train_scaled, y_train, \\\n",
    "    X_validate_scaled, y_validate, \\\n",
    "    X_test_scaled, y_test = wrangle_tips('tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex  smoker  day    time  size  sex  smoker  time\n",
       "0         NaN   NaN     NaN     NaN  NaN     NaN   NaN  1.0     0.0   0.0\n",
       "1       16.99  1.01  Female      No  Sun  Dinner   2.0  0.0     1.0   0.0\n",
       "2       10.34  1.66    Male      No  Sun  Dinner   3.0  0.0     0.0   0.0\n",
       "3       21.01  3.50    Male      No  Sun  Dinner   3.0  0.0     0.0   1.0\n",
       "4       23.68  3.31    Male      No  Sun  Dinner   2.0  NaN     NaN   NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check of the columns\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_explore.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a. Create a column named tip_percentage. This should be the tip amount divided by the total bill."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating my tip_percentage column in tips df\n",
    "\n",
    "df['tip_percentage'] = df['tip'] / df['total_bill']\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b. Create a column named price_per_person. This should be the total bill divided by the party size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating my price_per_person column in tips df\n",
    "\n",
    "df['price_per_person'] = df['total_bill'] / df['size']\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1c. Before using any of the methods discussed in the lesson, which features do you think would be most important for predicting the tip amount? The tip percentage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1d. Use all the other numeric features to predict tip amount. Use select k best and recursive feature elimination to select the top 2 features. What are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1e. Use all the other numeric features to predict tip percentage. Use select k best and recursive feature elimination to select the top 2 features. What are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1f. Why do you think select k best and recursive feature elimination might give different answers for the top features? Does this change as you change the number of features your are selecting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a function named select_kbest that takes in the predictors (X), the target (y), and the number of features to select (k) and returns the names of the top k selected features based on the SelectKBest class. Test your function with the tips dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a function named rfe that takes in the predictors, the target, and the number of features to select. It should return the top k features based on the RFE class. Test your function with the tips dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Load the swiss dataset and use all the other features to predict Fertility. Find the top 3 features using both select k best and recursive feature elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
